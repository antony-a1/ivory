package com.ambiata.ivory
package example

import com.ambiata.mundane.cli.OptionsParser
import scalaz._, Scalaz._
import org.apache.hadoop.fs.Path
import com.ambiata.ivory.core.{Dictionary, S3Repository, Repository}
import com.ambiata.saws.core.S3Action
import S3Action._
import com.ambiata.ivory.storage.legacy._
import com.ambiata.ivory.ingest._
import com.ambiata.ivory.alien.hdfs._
import scoobi._
import ScoobiS3EMRAction._
import com.ambiata.mundane.io._
import com.ambiata.ivory.alien.hdfs
import com.nicta.scoobi.core.ScoobiConfiguration
import org.joda.time.DateTimeZone

/**
 * This is an example of an application generating features and
 * storing them in ivory on S3
 */
object S3Workflow extends OptionsParser[WorkflowOptions] {

  def run(options: WorkflowOptions) {

    for {
           // create a Repository on S3
      repository <- createS3Repository(options.repositoryBucket, options.repositoryKey)

           // create a dictionary
           // the file must contain entries of format: namespace|name|encoding|type|description
      dictionary <- createDictionary(repository, options.dictionaryName, options.dictionaryPath)

          // generate sample features on HDFS as if
          // they were generated by Hive
          // we just expect the generated features to be produced as a factset file: https://github.com/ambiata/ivory#fact-sets
          // the name of the file is the name of the factset
          // each line has the form
          // entityId|feature name|feature value|datetime YYYY-MM-DD hh:mm:ss
      _ <- generateFeatures(repository, dictionary, options.namespace, options.factsetName, options.factsetPath)

      _ <- createFactSet(repository, dictionary, options.factsetName, options.namespace, options.factsetPath, options.timezone)

           // then we create a feature store for our fact sets
           // we first validate the features with the dictionary and
      _ <- createFeatureStore(repository, options.storeName, options.storePath)

           // extract a snapshot
      _ <- extractSnapshot(repository, options)
    } yield ()
  }

  def generateFeatures(repository: S3Repository, dictionary: Dictionary, namespace: String, factsetName: String,
                       generationPath: FilePath): ScoobiS3EMRAction[Unit] = {
    val emails =
    """|1111191|has.email|true|1979-10-17 00:00:00
       |2222242|has.email|false|1979-10-17 00:00:00
       |3333253|has.email|true|1979-10-17 00:00:00
       |4444924|has.email|true|1979-10-17 00:00:00
       |5555655|has.email|true|1979-10-17 00:00:00
       |6666106|has.email|true|1979-10-17 00:00:00""".stripMargin
    ScoobiS3EMRAction.fromHdfs(Hdfs.writeWith(new Path(generationPath.path), os => Streams.write(os, emails)))
  }

  /**
   * create paths on s3 with empty files for dictionaries, stores and factsets
   * will fail right away if this simple creation can not be performed (bucket not accessible for example)
   */
  def createS3Repository(bucket: String, key: String): ScoobiS3EMRAction[S3Repository] =
    ScoobiS3EMRAction.fromS3Action(CreateRepository.onS3(Repository.fromS3(FilePath(bucket) </> key)))

  /**
   * create a dictionary found at dictionaryPath.
   *
   * If the dictionary is valid, store it on S3, otherwise fail
   */
  def createDictionary(repository: S3Repository, dictionaryName: String, dictionaryPath: FilePath): ScoobiS3EMRAction[Dictionary] = {
    val dictionaryPath = new FilePath("target/test/dictionary.psv")
    val dictionary = """entity|has.email|boolean|categorical|true if the customer has an email address|â˜ """

    for {
      _          <- ScoobiS3EMRAction.fromHdfs(hdfs.Hdfs.writeWith(new Path(dictionaryPath.path), os => Streams.write(os, dictionary)))
      dictionary <- ScoobiS3EMRAction.fromHdfsS3(DictionaryImporter.onS3("ambiata-dev-app" </> "customer/ivory/repository1/", "dictionary1", dictionaryPath))
    } yield dictionary
  }


  def createFactSet(repository: S3Repository, dictionary: Dictionary, factsetName: String, namespace: String,
                    factsetPath: FilePath, timezone: DateTimeZone): ScoobiS3EMRAction[Unit] = for {
    clusterId <- ScoobiS3EMRAction.safe(Option(System.getenv("EMR_CLUSTER_ID")))
    _         <- ScoobiS3EMRAction.reader { sc: ScoobiConfiguration =>
                   clusterId.foreach(c => sc.set("EMR_CLUSTER_ID", c))
                   EavtTextImporter.onS3(repository, dictionary, factsetName, namespace, factsetPath, timezone, None).runScoobi(sc)
                 }
  } yield ()



  def createFeatureStore(repository: S3Repository, storeName: String, storePath: FilePath): ScoobiS3EMRAction[Unit] =
    ScoobiS3EMRAction.fromHdfsS3(FeatureStoreImporter.onS3(repository, storeName, storePath))

  def extractSnapshot(repository: Repository, options: WorkflowOptions): ScoobiS3EMRAction[Unit] =
    ScoobiS3EMRAction.safe(())

  def main(args: Array[String]) {
    parse(args, WorkflowOptions()).fold (
      message => println(message),
      opts    => run(opts)
    )
  }

  opt[String]("repo-bucket").required.action { (a, c) => c.copy(repositoryBucket = a) }
  opt[String]("repo-key").required.action { (a, c) => c.copy(repositoryKey = a) }

  opt[String]("dictionary-path").required.action { (a, c) => c.copy(dictionaryPath = new FilePath(a)) }
  opt[String]("dictionary-name").required.action { (a, c) => c.copy(dictionaryName = a) }

  opt[String]("namespace").required.action { (a, c) => c.copy(namespace = a) }

  opt[String]("factset-path").required.action { (a, c) => c.copy(factsetPath = new FilePath(a)) }
  opt[String]("factset-name").required.action { (a, c) => c.copy(factsetName = a) }

  opt[String]("store-path").required.action { (a, c) => c.copy(storePath = new FilePath(a)) }
  opt[String]("store-name").required.action { (a, c) => c.copy(storeName = a) }

  opt[String]("timezone").required.action { (a, c) => c.copy(timezone = DateTimeZone.forID(a)) }
}

case class WorkflowOptions(
  repositoryBucket: String = "s3://ambiata-test/",
  repositoryKey: String = "ivory/test",
  dictionaryPath: FilePath = new FilePath("dictionary"),
  dictionaryName: String = "dictionary",
  factsetName: String = "test",
  namespace: String = "ns",
  factsetPath: FilePath = new FilePath("generated"),
  storePath: FilePath = new FilePath("store"),
  storeName: String = "store",
  timezone: DateTimeZone = DateTimeZone.getDefault)
